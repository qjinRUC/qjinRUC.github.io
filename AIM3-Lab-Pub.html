<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Title -->
    <title>AI·M³-Publication</title>

    <!-- Required Meta Tags Always Come First -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <!-- Favicon -->
    <link rel="shortcut icon" href="./images/favicon.png">

    <!-- Google Fonts -->
    <!-- <link href="https://fonts.googleapis.com/css?family=Barlow:300,400,400i,500,700%7CAlegreya:400" rel="stylesheet"> -->

    <!-- CSS Global Compulsory -->
    <link rel="stylesheet" href="./css/vendor/bootstrap/bootstrap.min.css">

    <!-- CSS Implementing Plugins -->
    <link rel="stylesheet" href="./css/vendor/icon-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="./css/vendor/icon-line-pro/style.css">
    <link rel="stylesheet" href="./css/vendor/icon-hs/style.css">
    <link rel="stylesheet" href="./css/vendor/icon-material/material-icons.css">
    <link rel="stylesheet" href="./css/vendor/animate.css">
    <link rel="stylesheet" href="./css/vendor/hs-megamenu/src/hs.megamenu.css">
    <link rel="stylesheet" href="./css/vendor/hamburgers/hamburgers.min.css">
    <link rel="stylesheet" href="./css/vendor/chosen/chosen.css">

    <!-- CSS Unify Theme -->
    <link rel="stylesheet" href="./css/styles.multipage-education.css">

    <!-- CSS Customization -->
    <link rel="stylesheet" href="./css/custom.css">
  </head>

  <body>
    <main>

      <!-- Header -->
      <header id="js-header" class="u-header">
        <div class="u-header__section">

          <div class="container">
            <!-- Nav -->
            <nav class="js-mega-menu navbar navbar-expand-lg g-px-0 g-py-5 g-py-0--lg">
              <!-- Logo -->
              <a class="navbar-brand g-max-width-170 g-max-width-200--lg" href="AIM3-Lab.html">
                <img class="img-fluid " src="./images/logo.png" alt="Logo">
              </a>
              <!-- End Logo -->

              <!-- Responsive Toggle Button -->
              <button class="navbar-toggler navbar-toggler-right btn g-line-height-1 g-brd-none g-pa-0" type="button"
                      aria-label="Toggle navigation"
                      aria-expanded="false"
                      aria-controls="navBar"
                      data-toggle="collapse"
                      data-target="#navBar">
                <span class="hamburger hamburger--slider g-px-0">
                  <span class="hamburger-box">
                    <span class="hamburger-inner"></span>
                  </span>
                </span>
              </button>
              <!-- End Responsive Toggle Button -->

              <!-- Navigation -->
              <div id="navBar" class="collapse navbar-collapse">
                <ul class="navbar-nav align-items-lg-center g-py-30 g-py-0--lg ml-auto">
                  <li class="nav-item">
                    <a class="nav-link g-color-primary--hover g-font-size-15 g-font-size-17--xl g-px-15--lg g-py-10 g-py-30--lg" href="AIM3-Lab.html">
                      Home
                    </a>
                  </li>
                  <li class="nav-item">
                    <a class="nav-link g-color-primary--hover g-font-size-15 g-font-size-17--xl g-px-15--lg g-py-10 g-py-30--lg" href="AIM3-Lab-Research.html">
                      Research
                    </a>
                  </li>
                  <li class="nav-item">
                    <a class="nav-link g-color-primary--hover g-font-size-15 g-font-size-17--xl g-px-15--lg g-py-10 g-py-30--lg" href="AIM3-Lab-Pub.html">
                      Publications
                    </a>
                  </li>
                  <li class="nav-item">
                    <a class="nav-link g-color-primary--hover g-font-size-15 g-font-size-17--xl g-px-15--lg g-py-10 g-py-30--lg" href="AIM3-Lab-People.html">
                      People
                    </a>
                  </li>
                  <li class="nav-item">
                    <a class="nav-link g-color-primary--hover g-font-size-15 g-font-size-17--xl g-pl-15--lg g-pr-0--lg g-py-10 g-py-30--lg" href="AIM3-Lab-Contact.html">
                      Concat
                    </a>
                  </li>
                </ul>
              </div>
              <!-- End Navigation -->
            </nav>
            <!-- End Nav -->
          </div>
        </div>
      </header>
      <!-- End Header -->

      <!-- Publications -->
      <div class="g-bg-secondary">
        <!-- Programs -->
        <div class="container g-pt-70 ">
          <div class="row">
            <div class="col-md-12 col-lg-12 g-mb-70">
              <div class="mb-5">
                <h2>Journal and Conference</h2>
              </div>

              <div class="g-px-15 mb-5">
                <!-- Heading -->
                <div class="row g-bg-main g-color-white g-font-size-16 g-py-15">
                  <div class="col-sm-10">
                    <div class="d-flex align-items-center">
                      <h2 class="h5 mb-0"><a class="u-link-v5 g-color-white-opacity-0_8 g-color-white--hover" >
                        Paper
                      </a></h2>
                    </div>
                  </div>
                  <div class="col-sm-2">
                    <div class="d-flex align-items-center">
                      <h3 class="h5 mb-0"><a class="u-link-v5 g-color-white-opacity-0_8 g-color-white--hover" >
                        Publisher
                      </a></h3>
                    </div>
                  </div>
                </div>
                <!-- End Heading -->

				

              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Context-aware Goodness of Pronunciation for Computer-Assisted Pronunciation Trainings</b><br>
                Jiatong Shi, Nan Huo, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  Interspeech, 2020. 
                </div>
              </div>				
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>VideoIC: A Video Interactive Comments Dataset and Multimodal Multitask Learning for Comments Generations</b><br>
                Weiying Wang, Jieting Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2020. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>ICECAP: Information Concentrated Entity-aware Image Captioning</b><br>
                Anwen Hu, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2020. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Semi-supervised Multi-modal Emotion Recognition with Cross-Modal Distribution Matching</b><br>
                Jingjun Liang, Ruichen Li, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2020. 
                </div>
              </div>				
                
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs</b><br>
                Shizhe Chen, Qin Jin, Peng Wang, Qi Wu</span>
                </div>
                <div class="col-sm-2">
                  CVPR, 2020. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning</b><br>
                Shizhe Chen, Yida Zhao, Qin Jin, Qi Wu</span>
                </div>
                <div class="col-sm-2">
                  CVPR, 2020. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Better Captioning With Sequence-Level Exploration</b><br>
                Jia Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  CVPR, 2020. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Skeleton-based Interactive Graph Network for Human Object Interaction Detection</b><br>
                Sipeng Zheng, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ICME, 2020. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal Data</b><br>
                Shizhe Chen, Qin Jin, Alexandar Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  AAAI, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Cross-culture Multimodal Emotion Recognition with Adversarial Learning</b><br>
                Jingjun Liang, Shizhe Chen, Jinming Zhao, Qin Jin, Haibo Liu, Li Lu</span>
                </div>
                <div class="col-sm-2">
                  ICASSP, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Activitynet 2019 Task 3:Exploring Contexts for Dense Captioning Events in Video</b><br>
                Shizhe Chen, Yuqing Song, Yida Zhao, Qin Jin,Zhaoyang Zeng, Bei Liu, Jianlong Fu, Alexander Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  CVPR 2019, ActivityNet Large Scale Activity Recognition Challenge. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>From Words to Sentences: A Progressive Learning Approach for Zero-resource Machine Translation with Visual Pivots</b><br>
                Shizhe Chen, Qin Jin, Jianlong Fu</span>
                </div>
                <div class="col-sm-2">
                  IJCAI, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Generating Video Descriptions With Latent Topic Guidance</b><br>
                Shizhe Chen, Qin Jin, Jia Chen, Alexander G. Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  IEEE TRANSACTIONS ON MULTIMEDIA, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Speech Emotion Recognition in Dyadic Dialogues</b><br>
                Jinming Zhao, Shizhe Chen, Jingjun Liang, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  INTERSPEECH, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Unpaired Cross-lingual Image Caption Generation with Self-Supervised Rewards</b><br>
                Yuqing Song, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Visual Relation Detection with Multi-Level Attention</b><br>
                Sipeng Zheng, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Neural Storyboard Artist: Visualizing Stories with Coherent Image Sequences</b><br>
                Shizhe Chen, Bei Liu, Jianlong Fu, Ruihua Song, Qin Jin, Pingping Lin, Xiaoyu Qi, Chunting Wang, Jin Zhou</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Relation Understanding in Videos</b><br>
                Sipeng Zheng, Xiangyu Chen, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, Grand Challenge: Relation Understanding in Videos, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Adversarial Domain Adaption for Multi-Cultural DimensionalEmotion Recognition in Dyadic Interactions</b><br>
                Jinming Zhao, Ruichen Li, Jingjun Liang, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  AVEC, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Integrating Temporal and Spatial Attentions for VATEX Video Captioning Challenge 2019</b><br>
                Shizhe Chen, Yida Zhao, Yuqing Song, Qin Jin, Qi Wu</span>
                </div>
                <div class="col-sm-2">
                  ICCV, VATEX Video Captioning Challenge 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension</b><br>
                Weiying Wang, Yongcheng Wang, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  EMNLP, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>RUC_AIM3 at TRECVID 2019: Video to Text</b><br>
                Yuqing Song, Yida Zhao, Shizhe Chen, Qin Jinn</span>
                </div>
                <div class="col-sm-2">
                  NIST TRECVID, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Semi-supervised Multimodal Emotion Recognition With Improved Wasserstein GANs</b><br>
                Jingjun Liang, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  APSIPA ASC, 2019. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>RUC+CMU: System Report for Dense Captioning Events in Videos</b><br>
                Shizhe Chen, Yuqing Song, Yida Zhao, Qin Jin, Alexandar Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  CVPR ActivityNet Large Scale Activity Recognition Challenge, 2018. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Class-aware Self-Attention for Audio Event Recognition</b><br>
                Shizhe Chen, Jia Chen, Qin Jin, Alexandar Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  ICMR, 2018. (Best Paper Runner-up) </span><br>
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Multimodal Dimensional and Continuous Emotion Recognition in Dyadic Video Interactions</b><br>
                Jinming Zhao, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  Pacific-Rim Conference on Multimedia (PCM), 2018. </span><br>
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>iMakeup: Makeup Instructional Video Dataset for Fine-grained Dense Video Captioning</b><br>
                Xiaozhu Lin, Qin Jin, Shizhe Chen, Yuqing Song, Yida Zhao</span>
                </div>
                <div class="col-sm-2">
                  Pacific-Rim Conference on Multimedia (PCM), 2018. </span><br>
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Multi-modal Multi-cultural Dimensional Continues Emotion Recognition in Dyadic Interactions</b><br>
                Jinming Zhao, Ruichen Li, Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia Audio-Visual Emotion Challenge (AVEC) Workshop, 2018. </span><br>
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Video Captioning with Guidance of Multimodal Latent Topics</b><br>
                Shizhe Chen, Jia Chen, Qin Jin, Alexandar Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2017. </span><br>                                 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Knowing Yourself: Improving Video Caption via In-depth Recap</b><br>
                Qin Jin, Shizhe Chen, Jia Chen, Alexandar Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2017. (Best Grand Challenge Paper) </span><br>
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Multimodal Multi-task Learning for Dimensional and Continuous Emotion Recognition</b><br>
                Shizhe Chen, Qin Jin, Jinming Zhao and Shuai Wang</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia Audio-Visual Emotion Challenge (AVEC) Workshop, 2017. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Generating Video Descriptions with Topic Guidance</b><br>
                Shizhe Chen, Jia Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ICMR, 2017.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Emotion Recognition with Multimodal Features and Temporal Models</b><br>
                Shuai Wang, Wenxuan Wang, Jinming Zhao, Shizhe Chen, Qin Jin, Shilei Zhang, Yong Qin</span>
                </div>
                <div class="col-sm-2">
                  ICMI, 2017.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Facial Action Units Detection with Multi-Features and-AUs Fusion</b><br>
                Xinrui Li, Shizhe Chen, and Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  Automatic Face &amp; Gesture Recognition (FGR), 2017.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Boosting Recommendation in Unexplored Categories by User Price Preference</b><br>
                Jia Chen, Qin Jin, Shiwan Zhao, Shenghua Bao, Li Zhang, Zhong Su, Yong Yu</span>
                </div>
                <div class="col-sm-2">
                  ACM Transactions on Information Systems (TOIS), 2016.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Video Emotion Recognition in the Wild Based on Fusion of Multimodal Features</b><br>
                Shizhe Chen, Xinrui Li, Qin Jin, Shilei Zhang, Yong Qin</span>
                </div>
                <div class="col-sm-2">
                  ICMI 2016.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Describing Videos using Multi-modal Fusion</b><br>
                Qin Jin, Jia Chen, Shizhe Chen, Yifan Xiong</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia, 2016. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Semantic Image Profiling for Historic Events: Linking Images to Phrases</b><br>
                Jia Chen, Qin Jin, Yifan Xiong</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia 2016. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Multi-modal Conditional Attention Fusion for Dimensional Emotion Prediction</b><br>
                Shizhe Chen, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia 2016.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>History Rhyme: Searching Historic Events by Multimedia Knowledge</b><br>
                Yifan Xiong, Jia Chen, Qin Jin, Chao Zhang</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia 2016. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Detecting Violence in Video using Subclasses</b><br>
                Xirong Li, Yujia Huo, Qin Jin, Jieping Xu</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia 2016. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Generating Natural Video Descriptions via Multimodal Processing</b><br>
                Qin Jin, Junwei Liang, Xiaozhu Lin</span>
                </div>
                <div class="col-sm-2">
                  Interspeech 2016. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Improving Image Captioning by Concept-based Sentence Reranking</b><br>
                Xirong Li, Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  Pacific-Rim Conference on Multimedia (PCM), 2016. (Best Paper Runner-up)
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Video Description Generation using Audio and Visual Cues</b><br>
                Qin Jin, Junwei Liang</span>
                </div>
                <div class="col-sm-2">
                  ICMR 2016.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Exploitation and Exploration Balanced Hierarchical Summary for Landmark Images</b><br>
                Jia Chen, Qin Jin, Shenghua Bao, Junfeng Ye, Zhong Su, Shimin Chen, Yong Yu</span>
                </div>
                <div class="col-sm-2">
                  IEEE Transactions on Multimedia (TMM), 2015
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Lead Curve Detection in Drawings with Complex Cross-Points</b><br>
                Jia Chen, Min Li, Qin Jin, Yongzhe Zhang, Shenghua Bao, Zhong Su, Yong Yu</span>
                </div>
                <div class="col-sm-2">
                  Neurocomputing, 2015, 168: 35-46.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Image Profiling for History Events on the Fly</b><br>
                Jia Chen, Qin Jin, Yong Yu, Alexander G. Hauptmann</span>
                </div>
                <div class="col-sm-2">
                  ACM Multimedia 2015.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Persistent B+-Trees in Non-Volatile Main Memory</b><br>
                Shimin Chen and Qin Jin</span>
                </div>
                <div class="col-sm-2">
                  VLDB, Hawaii, USA, 2015 (VLDB’15).
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Semantic Concept Annotation for User Generated Videos Using Soundtracks</b><br>
                Qin Jin, Junwei Liang, Xixi He, Gang Yang, Jieping Xu, Xirong Li,</span>
                </div>
                <div class="col-sm-2">
                  ICMR 2015.
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Speech Emotion Recognition With Acoustic And Lexical Features</b><br>
                Qin Jin, Chengxin Li, Shizhe Chen, Huimin Wu</span>
                </div>
                <div class="col-sm-2">
                  ICASSP, 2015. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Detecting Semantic Concepts In Consumer Videos Using Audio</b><br>
                Junwei Liang, Qin Jin, Xixi He, Gang Yang, Jieping Xu, Xirong Li</span>
                </div>
                <div class="col-sm-2">
                  ICASSP, 2015. 
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Does Product Recommendation Meet its Waterloo in Unexplored Categories? No, Price Comes to Help</b><br>
                Jia Chen, Qin Jin, Shiwan Zhao, Shenghua Bao, Li Zhang, Zhong Su, Yong Yu</span>
                </div>
                <div class="col-sm-2">
                  SIGIR 2014 (SIGIR’14).</span><br>
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b>Semantic Concept Annotation of Consumer Videos at Frame-level Using Audio</b><br>
                Junwei Liang, Qin Jin, Xixi He, Xirong Li, Gang Yang, Jieping Xu</span>
                </div>
                <div class="col-sm-2">
                  Pacific-rim Conference on Multimedia 2014 (PCM’14).</span><br>
                </div>
              </div>
              <div class="row g-brd-around g-brd-top-none g-brd-secondary-light-v2 g-font-size-16 g-py-15">
                <div class="col-sm-10">
                <span><b> Speech Emotion Classification using Acoustic Features</b><br>
                Shizhe Chen, Qin Jin, Xirong Li, Gang Yang, Jieping Xu</span>
                </div>
                <div class="col-sm-2">
                  ISCSLP, 2014.</span><br>
                </div>
              </div>
              </div>

            </div>

          </div>
        </div>
        <!-- End Programs -->
      </div>
      <!-- End Publications-->

      <!-- Footer -->
      <footer class="g-bg-secondary g-pt-100 g-pb-50">
        <div class="container">
          <!-- Footer Copyright -->
          <div class="row justify-content-lg-center align-items-center text-center">
            <div class="col-sm-5 col-md-5 col-lg-5 order-md-3 g-mb-30">
              <a class="u-link-v5 g-color-text g-color-primary--hover" >
                <i class="align-middle mr-2 icon-real-estate-027 u-line-icon-pro"></i>
                Renmin University, Beijing, China
              </a>
            </div>

            <div class="col-md-4 col-lg-3 order-md-1 g-mb-30">
              <p class="g-color-text mb-0">AI·M³ Lab</p>
            </div>
          </div>
          <!-- End Footer Copyright -->
        </div>
      </footer>
      <!-- End Footer -->

      <!-- Go to Top -->
      <a class="js-go-to u-go-to-v1 u-shadow-v32 g-width-40 g-height-40 g-color-primary g-color-white--hover g-bg-white g-bg-main--hover g-bg-main--focus g-font-size-12 rounded-circle" href="#" data-type="fixed" data-position='{
       "bottom": 15,
       "right": 15
     }' data-offset-top="400"
        data-compensation="#js-header"
        data-show-effect="slideInUp"
        data-hide-effect="slideInDown">
        <i class="hs-icon hs-icon-arrow-top"></i>
      </a>
      <!-- End Go to Top -->
    </main>

    <!-- JS Global Compulsory -->
    <script src="./css/vendor/jquery/jquery.min.js"></script>
    <script src="./css/vendor/jquery-migrate/jquery-migrate.min.js"></script>
    <script src="./css/vendor/popper.min.js"></script>
    <script src="./css/vendor/bootstrap/bootstrap.min.js"></script>

    <!-- JS Implementing Plugins -->
    <script src="./css/vendor/hs-megamenu/src/hs.megamenu.js"></script>
    <script src="./css/vendor/chosen/chosen.jquery.js"></script>

    <!-- JS Unify -->
    <script src="./js/hs.core.js"></script>
    <script src="./js/components/hs.header.js"></script>
    <script src="./js/helpers/hs.hamburgers.js"></script>
    <script src="./js/components/hs.dropdown.js"></script>
    <script src="./js/components/hs.select.js"></script>
    <script src="./js/components/hs.sticky-block.js"></script>
    <script src="./js/components/hs.go-to.js"></script>

    <!-- JS Customization -->
    <script src="./js/custom.js"></script>

    <!-- JS Plugins Init. -->
    <script>
      $(document).on('ready', function () {
        // initialization of header
        $.HSCore.components.HSHeader.init($('#js-header'));
        $.HSCore.helpers.HSHamburgers.init('.hamburger');

        // initialization of HSMegaMenu component
        $('.js-mega-menu').HSMegaMenu({
          event: 'hover',
          pageContainer: $('.container'),
          breakpoint: 991
        });

        // initialization of HSDropdown component
        $.HSCore.components.HSDropdown.init($('[data-dropdown-target]'), {
          afterOpen: function () {
            $(this).find('input[type="search"]').focus();
          }
        });

        // initialization of custom select
        $.HSCore.components.HSSelect.init('.js-custom-select');

        // initialization of sticky blocks
        setTimeout(function() {
          $.HSCore.components.HSStickyBlock.init('.js-sticky-block');
        }, 300);

        // initialization of go to
        $.HSCore.components.HSGoTo.init('.js-go-to');
      });
    </script>
  </body>
</html>
